- Code refcator.
   - For existing pipelines
   - unsersatnd the logic 
   - following best software parctices, variable dfeination, breaking complex logic into small managle steps, functions. 
   - Modular and reusability and easier to maintain
   - package into code for reusability
- Data Testing
  - Design a testing frameworks for validationn the pipeliene outputs
  - Testing depends on outputs type of the some column types numerics, and complex data such as text espically our team deal with text, and Embeddings.
  - carried out whereevr code reafctor make sure logic still and converting to pyspark code.   
  - challenges scale up tesing on few thousands to ensure we dont out on corner cases. I would like to quote a recent  
- Model Deployment
  - set a little context on why this was needed mainly due to experiment how it was conducted before and chhalleges.
  - Giev back drop of NLI model on which model was used. Automate 
  - add a screenshot for following
    - used parameters in the experimentation
    - link for experimentation and customization 
- add link to latest MLFlow experiment
   - and 
https://pages.github.voya.net/Voya/data-science-nlp-centralized-nlp-package/_build/html/index.html