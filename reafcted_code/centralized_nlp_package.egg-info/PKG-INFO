Metadata-Version: 2.1
Name: centralized_nlp_package
Version: 0.1.0
Summary: A centralized, modular Python package for NLP pipelines on Databricks.
Home-page: https://github.com/your_username/centralized_nlp_package
Author: Santhosh Kumar
Author-email: santhosh.kumar3@voya.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: pandas
Requires-Dist: numpy
Requires-Dist: dask
Requires-Dist: pyarrow
Requires-Dist: gensim
Requires-Dist: spacy
Requires-Dist: plotly
Requires-Dist: umap-learn
Requires-Dist: loguru
Requires-Dist: hydra-core

# Centralized NLP Package

A centralized, modular, and scalable Python package for managing multiple NLP pipelines on Databricks. This package consolidates common functionalities for distribution to various stakeholders.

## Features

- **Data Access:** Seamlessly interact with Snowflake databases.
- **Preprocessing:** Efficient text tokenization, lemmatization, and n-gram processing.
- **Embedding Generation:** Train and manage Word2Vec models with optional bigram support.
- **Visualization:** Create interactive UMAP visualizations for embeddings.
- **Scalability:** Utilize Dask for parallel processing and handle large-scale data.
- **Configuration Management:** Flexible and modular configurations using Hydra.
- **Logging:** Structured logging with Loguru for easy debugging and monitoring.

## Installation

You can install the package using `pip`:

```bash
pip install centralized_nlp_package
