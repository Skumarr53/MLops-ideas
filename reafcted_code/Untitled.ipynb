{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9192c3b-b720-4911-9342-731b0c529d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pdb import set_trace\n",
    "from pyspark.sql.functions import udf, col, size, expr\n",
    "from pyspark.sql.types import ArrayType, StringType, FloatType, IntegerType, StructType, StructField, TimestampType\n",
    "import json\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab1b5887-853a-467b-ba43-170b686cdd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu121\n",
      "CUDA available: True\n",
      "GPU Device Name: NVIDIA GeForce GTX 1660\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40a89bd4-bd77-45be-a710-69fd49a3ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86c1da69-c080-43ad-859a-58a6c4d49ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, StringType, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Constants (Ensure these are correctly defined)\n",
    "MODEL_FOLDER_PATH = \"~/.cache/huggingface/hub/\"  # Update this path\n",
    "MODEL_NAME = \"models--MoritzLaurer--deberta-v3-large-zeroshot-v2\"\n",
    "ENABLE_QUANTIZATION = False\n",
    "BATCH_SIZE = 1  # Adjust based on your GPU capacity\n",
    "\n",
    "# Step 2: Initialize Logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(\"NLI_Inference\")\n",
    "\n",
    "# Initialize a global variable for the pipeline\n",
    "nli_pipeline = None\n",
    "\n",
    "def initialize_nli_pipeline(enable_quantization=False):\n",
    "    global nli_pipeline\n",
    "    try:\n",
    "        # Load the tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        \n",
    "        # Load the model\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        \n",
    "        if enable_quantization:\n",
    "            model = torch.quantization.quantize_dynamic(\n",
    "                model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "            )\n",
    "            logger.info(\"Model quantization enabled.\")\n",
    "        else:\n",
    "            logger.info(\"Model quantization disabled.\")\n",
    "        \n",
    "        device = -1 if torch.cuda.is_available() else -1\n",
    "        nli_pipeline = pipeline(\n",
    "            task=\"zero-shot-classification\",  # Changed task\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device=device\n",
    "        )\n",
    "        logger.info(f\"NLI pipeline initialized on device: {'GPU' if device == 0 else 'CPU'}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize NLI pipeline: {e}\")\n",
    "        raise e\n",
    "\n",
    "# Define the schema for the inference results\n",
    "inference_schema = ArrayType(StructType([\n",
    "    StructField(\"label\", StringType(), False),\n",
    "    StructField(\"score\", FloatType(), False)\n",
    "]))\n",
    "\n",
    "@pandas_udf(inference_schema, PandasUDFType.SCALAR_ITER)\n",
    "def md_inference_udf(iterator):\n",
    "    global nli_pipeline\n",
    "    if nli_pipeline is None:\n",
    "        initialize_nli_pipeline(enable_quantization=ENABLE_QUANTIZATION)\n",
    "    \n",
    "    for batch_num, batch in enumerate(iterator, start=1):\n",
    "        logger.info(f\"Processing MD inference batch {batch_num} with {len(batch)} rows.\")\n",
    "        try:\n",
    "            # Each 'batch' is a Pandas Series containing lists of text pairs\n",
    "            # Flatten the list of text pairs in the batch\n",
    "            flat_text_pairs = [pair for sublist in batch for pair in sublist]\n",
    "            logger.debug(f\"Batch {batch_num}: Total text pairs to infer: {len(flat_text_pairs)}\")\n",
    "            \n",
    "            if len(flat_text_pairs):\n",
    "                # Perform inference in batch using zero-shot-classification pipeline\n",
    "                results = nli_pipeline(\n",
    "                    sequences=flat_text_pairs,\n",
    "                    candidate_labels=[\n",
    "                        \"This text is about consumer strength\",\n",
    "                        \"This text is about consumer weakness\",\n",
    "                        \"This text is about reduced consumer's spending patterns\"\n",
    "                    ],\n",
    "                    multi_class=True,\n",
    "                    batch_size=BATCH_SIZE\n",
    "                )\n",
    "                logger.debug(f\"Batch {batch_num}: Inference completed with {len(results)} results.\")\n",
    "            else:\n",
    "                results = []\n",
    "            \n",
    "            # Split results back to original rows\n",
    "            split_results = []\n",
    "            idx = 0\n",
    "            for pairs in batch:\n",
    "                if len(pairs):\n",
    "                    # Extract the relevant slice of results\n",
    "                    row_results = results[idx:idx+len(pairs)]\n",
    "                    # Transform each result into a list of dicts with 'label' and 'score'\n",
    "                    formatted_results = [\n",
    "                        {\"label\": res['labels'][i], \"score\": res['scores'][i]}\n",
    "                        for res in row_results\n",
    "                        for i in range(len(res['labels']))\n",
    "                    ]\n",
    "                    split_results.append(formatted_results)\n",
    "                    idx += len(pairs)\n",
    "                else:\n",
    "                    split_results.append([])\n",
    "            \n",
    "            yield pd.Series(split_results)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in MD inference batch {batch_num}: {e}\")\n",
    "            # Yield empty results for this batch to continue processing\n",
    "            yield pd.Series([[] for _ in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d62080c-6e51-4202-8a57-12318b4e95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = [\n",
    "    {\n",
    "        \"id\": \"1\",\n",
    "        \"TEXT_PAIRS_MD\": [\n",
    "            [\"Consumers are showing increased confidence in the market, leading to higher spending.<s><s>This text is about consumer strength\"],\n",
    "            [\"There is a noticeable decline in consumer purchasing behavior this quarter.<s><s>This text is about consumer weakness\"]\n",
    "        ]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5993530e-310d-435c-b689-d87ba15b5365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 11:48:47 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Got job 30 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Final stage: ResultStage 30 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:48:47 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 14.7 KiB, free 366.1 MiB)\n",
      "24/09/25 11:48:47 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 366.1 MiB)\n",
      "24/09/25 11:48:47 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 192.168.1.6:41915 (size: 7.2 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:47 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 111) (192.168.1.6, executor driver, partition 0, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO Executor: Running task 0.0 in stage 30.0 (TID 111)\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 45, boot = 4, init = 41, finish = 0\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 0.0 in stage 30.0 (TID 111). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 111) in 51 ms on 192.168.1.6 (executor driver) (1/1)\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:48:47 INFO DAGScheduler: ResultStage 30 (showString at NativeMethodAccessorImpl.java:0) finished in 0.058 s\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Job 30 finished: showString at NativeMethodAccessorImpl.java:0, took 0.060599 s\n",
      "24/09/25 11:48:47 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Got job 31 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Final stage: ResultStage 31 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:48:47 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 14.7 KiB, free 366.1 MiB)\n",
      "24/09/25 11:48:47 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 366.1 MiB)\n",
      "24/09/25 11:48:47 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 192.168.1.6:41915 (size: 7.2 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:47 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 31 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Adding task set 31.0 with 4 tasks resource profile 0\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 112) (192.168.1.6, executor driver, partition 1, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 113) (192.168.1.6, executor driver, partition 2, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 114) (192.168.1.6, executor driver, partition 3, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 115) (192.168.1.6, executor driver, partition 4, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO Executor: Running task 0.0 in stage 31.0 (TID 112)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 1.0 in stage 31.0 (TID 113)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 3.0 in stage 31.0 (TID 115)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 2.0 in stage 31.0 (TID 114)\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 42, boot = 0, init = 42, finish = 0\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 0.0 in stage 31.0 (TID 112). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 112) in 47 ms on 192.168.1.6 (executor driver) (1/4)\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 47, boot = 5, init = 41, finish = 1\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 1.0 in stage 31.0 (TID 113). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 113) in 53 ms on 192.168.1.6 (executor driver) (2/4)\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 51, boot = 8, init = 43, finish = 0\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 3.0 in stage 31.0 (TID 115). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 115) in 57 ms on 192.168.1.6 (executor driver) (3/4)\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 55, boot = 13, init = 42, finish = 0\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 2.0 in stage 31.0 (TID 114). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 114) in 61 ms on 192.168.1.6 (executor driver) (4/4)\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:48:47 INFO DAGScheduler: ResultStage 31 (showString at NativeMethodAccessorImpl.java:0) finished in 0.068 s\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Job 31 finished: showString at NativeMethodAccessorImpl.java:0, took 0.071664 s\n",
      "24/09/25 11:48:47 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Got job 32 (showString at NativeMethodAccessorImpl.java:0) with 7 output partitions\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Final stage: ResultStage 32 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:48:47 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 14.7 KiB, free 366.1 MiB)\n",
      "24/09/25 11:48:47 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 366.1 MiB)\n",
      "24/09/25 11:48:47 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 192.168.1.6:41915 (size: 7.2 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:47 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 32 (MapPartitionsRDD[70] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11))\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Adding task set 32.0 with 7 tasks resource profile 0\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 116) (192.168.1.6, executor driver, partition 5, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 117) (192.168.1.6, executor driver, partition 6, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 118) (192.168.1.6, executor driver, partition 7, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 3.0 in stage 32.0 (TID 119) (192.168.1.6, executor driver, partition 8, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 4.0 in stage 32.0 (TID 120) (192.168.1.6, executor driver, partition 9, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 5.0 in stage 32.0 (TID 121) (192.168.1.6, executor driver, partition 10, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 6.0 in stage 32.0 (TID 122) (192.168.1.6, executor driver, partition 11, PROCESS_LOCAL, 9270 bytes) \n",
      "24/09/25 11:48:47 INFO Executor: Running task 0.0 in stage 32.0 (TID 116)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 1.0 in stage 32.0 (TID 117)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 3.0 in stage 32.0 (TID 119)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 2.0 in stage 32.0 (TID 118)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 4.0 in stage 32.0 (TID 120)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 5.0 in stage 32.0 (TID 121)\n",
      "24/09/25 11:48:47 INFO Executor: Running task 6.0 in stage 32.0 (TID 122)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |TEXT_PAIRS_MD                                                                                                                                                                                                                                               |\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |[[Consumers are showing increased confidence in the market, leading to higher spending.<s><s>This text is about consumer strength], [There is a noticeable decline in consumer purchasing behavior this quarter.<s><s>This text is about consumer weakness]]|\n",
      "+---+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 42, boot = -13, init = 55, finish = 0\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 4.0 in stage 32.0 (TID 120). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 41, boot = 3, init = 38, finish = 0\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 4.0 in stage 32.0 (TID 120) in 54 ms on 192.168.1.6 (executor driver) (1/7)\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 1.0 in stage 32.0 (TID 117). 1886 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 117) in 58 ms on 192.168.1.6 (executor driver) (2/7)\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 55, boot = -1, init = 56, finish = 0\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 54, boot = 5, init = 49, finish = 0\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 3.0 in stage 32.0 (TID 119). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 2.0 in stage 32.0 (TID 118). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 3.0 in stage 32.0 (TID 119) in 70 ms on 192.168.1.6 (executor driver) (3/7)\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 118) in 70 ms on 192.168.1.6 (executor driver) (4/7)\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 51, boot = 5, init = 45, finish = 1\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 51, boot = 8, init = 43, finish = 0\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 6.0 in stage 32.0 (TID 122). 2087 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 0.0 in stage 32.0 (TID 116). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 6.0 in stage 32.0 (TID 122) in 79 ms on 192.168.1.6 (executor driver) (5/7)\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 116) in 80 ms on 192.168.1.6 (executor driver) (6/7)\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 59, boot = 14, init = 45, finish = 0\n",
      "24/09/25 11:48:47 INFO Executor: Finished task 5.0 in stage 32.0 (TID 121). 1843 bytes result sent to driver\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Finished task 5.0 in stage 32.0 (TID 121) in 87 ms on 192.168.1.6 (executor driver) (7/7)\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:48:47 INFO DAGScheduler: ResultStage 32 (showString at NativeMethodAccessorImpl.java:0) finished in 0.096 s\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Job 32 finished: showString at NativeMethodAccessorImpl.java:0, took 0.100646 s\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NLI_Inference_Test\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"id\", StringType(), False),\n",
    "    StructField(\"TEXT_PAIRS_MD\", ArrayType(ArrayType(StringType())), False)  # Array of arrays of strings\n",
    "])\n",
    "\n",
    "# Create the Spark DataFrame\n",
    "sample_df = spark.createDataFrame(data, schema=schema)\n",
    "\n",
    "# Display the DataFrame\n",
    "sample_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "943426a1-4f3b-4265-8de7-690f9c43175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 11:48:47 INFO CodeGenerator: Code generated in 6.810579 ms\n",
      "24/09/25 11:48:47 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Got job 33 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Final stage: ResultStage 33 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[75] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:48:47 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 33.9 KiB, free 366.0 MiB)\n",
      "24/09/25 11:48:47 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 366.0 MiB)\n",
      "24/09/25 11:48:47 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 192.168.1.6:41915 (size: 16.3 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:47 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:48:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[75] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/25 11:48:47 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0\n",
      "24/09/25 11:48:47 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 123) (192.168.1.6, executor driver, partition 0, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:47 INFO Executor: Running task 0.0 in stage 33.0 (TID 123)\n",
      "24/09/25 11:48:47 INFO CodeGenerator: Code generated in 7.849859 ms\n",
      "24/09/25 11:48:47 INFO PythonRunner: Times: total = 42, boot = -81, init = 123, finish = 0\n",
      "24/09/25 11:48:54 INFO ArrowPythonRunner: Times: total = 6415, boot = 3, init = 4526, finish = 1886\n",
      "24/09/25 11:48:54 INFO Executor: Finished task 0.0 in stage 33.0 (TID 123). 2137 bytes result sent to driver\n",
      "24/09/25 11:48:54 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 123) in 6432 ms on 192.168.1.6 (executor driver) (1/1)\n",
      "24/09/25 11:48:54 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:48:54 INFO DAGScheduler: ResultStage 33 (showString at NativeMethodAccessorImpl.java:0) finished in 6.437 s\n",
      "24/09/25 11:48:54 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:48:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished\n",
      "24/09/25 11:48:54 INFO DAGScheduler: Job 33 finished: showString at NativeMethodAccessorImpl.java:0, took 6.439349 s\n",
      "24/09/25 11:48:54 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:48:54 INFO DAGScheduler: Got job 34 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions\n",
      "24/09/25 11:48:54 INFO DAGScheduler: Final stage: ResultStage 34 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:48:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:48:54 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:48:54 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[75] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:48:54 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 33.9 KiB, free 366.0 MiB)\n",
      "24/09/25 11:48:54 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 366.0 MiB)\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 192.168.1.6:41915 (size: 16.3 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:54 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 192.168.1.6:41915 in memory (size: 7.2 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:54 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 34 (MapPartitionsRDD[75] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "24/09/25 11:48:54 INFO TaskSchedulerImpl: Adding task set 34.0 with 4 tasks resource profile 0\n",
      "24/09/25 11:48:54 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 124) (192.168.1.6, executor driver, partition 1, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:54 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 125) (192.168.1.6, executor driver, partition 2, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:54 INFO TaskSetManager: Starting task 2.0 in stage 34.0 (TID 126) (192.168.1.6, executor driver, partition 3, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 192.168.1.6:41915 in memory (size: 7.2 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:54 INFO TaskSetManager: Starting task 3.0 in stage 34.0 (TID 127) (192.168.1.6, executor driver, partition 4, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:48:54 INFO Executor: Running task 0.0 in stage 34.0 (TID 124)\n",
      "24/09/25 11:48:54 INFO Executor: Running task 1.0 in stage 34.0 (TID 125)\n",
      "24/09/25 11:48:54 INFO Executor: Running task 2.0 in stage 34.0 (TID 126)\n",
      "24/09/25 11:48:54 INFO Executor: Running task 3.0 in stage 34.0 (TID 127)\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 192.168.1.6:41915 in memory (size: 16.4 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 192.168.1.6:41915 in memory (size: 16.3 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 192.168.1.6:41915 in memory (size: 7.2 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 192.168.1.6:41915 in memory (size: 7.2 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 192.168.1.6:41915 in memory (size: 7.2 KiB, free: 366.3 MiB)\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 192.168.1.6:41915 in memory (size: 7.2 KiB, free: 366.3 MiB)\n",
      "24/09/25 11:48:54 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 192.168.1.6:41915 in memory (size: 16.4 KiB, free: 366.3 MiB)\n",
      "24/09/25 11:48:54 INFO PythonRunner: Times: total = 41, boot = -6543, init = 6584, finish = 0\n",
      "24/09/25 11:48:54 INFO PythonRunner: Times: total = 41, boot = -6531, init = 6572, finish = 0\n",
      "24/09/25 11:48:54 INFO PythonRunner: Times: total = 42, boot = -6540, init = 6582, finish = 0\n",
      "24/09/25 11:48:54 INFO PythonRunner: Times: total = 42, boot = -6532, init = 6574, finish = 0\n",
      "24/09/25 11:48:56 INFO ArrowPythonRunner: Times: total = 2309, boot = 306, init = 1, finish = 2002\n",
      "24/09/25 11:48:56 INFO Executor: Finished task 0.0 in stage 34.0 (TID 124). 2137 bytes result sent to driver\n",
      "24/09/25 11:48:56 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 124) in 2322 ms on 192.168.1.6 (executor driver) (1/4)\n",
      "24/09/25 11:49:01 INFO ArrowPythonRunner: Times: total = 6922, boot = 4, init = 4860, finish = 2058\n",
      "24/09/25 11:49:01 INFO Executor: Finished task 2.0 in stage 34.0 (TID 126). 2137 bytes result sent to driver\n",
      "24/09/25 11:49:01 INFO TaskSetManager: Finished task 2.0 in stage 34.0 (TID 126) in 6934 ms on 192.168.1.6 (executor driver) (2/4)\n",
      "24/09/25 11:49:01 INFO ArrowPythonRunner: Times: total = 6934, boot = 9, init = 4884, finish = 2041\n",
      "24/09/25 11:49:01 INFO Executor: Finished task 1.0 in stage 34.0 (TID 125). 2137 bytes result sent to driver\n",
      "24/09/25 11:49:01 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 125) in 6947 ms on 192.168.1.6 (executor driver) (3/4)\n",
      "24/09/25 11:49:01 INFO ArrowPythonRunner: Times: total = 7513, boot = 13, init = 4877, finish = 2623\n",
      "24/09/25 11:49:01 INFO Executor: Finished task 3.0 in stage 34.0 (TID 127). 2137 bytes result sent to driver\n",
      "24/09/25 11:49:01 INFO TaskSetManager: Finished task 3.0 in stage 34.0 (TID 127) in 7525 ms on 192.168.1.6 (executor driver) (4/4)\n",
      "24/09/25 11:49:01 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:49:01 INFO DAGScheduler: ResultStage 34 (showString at NativeMethodAccessorImpl.java:0) finished in 7.546 s\n",
      "24/09/25 11:49:01 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:49:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished\n",
      "24/09/25 11:49:01 INFO DAGScheduler: Job 34 finished: showString at NativeMethodAccessorImpl.java:0, took 7.549076 s\n",
      "24/09/25 11:49:01 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:49:01 INFO DAGScheduler: Got job 35 (showString at NativeMethodAccessorImpl.java:0) with 7 output partitions\n",
      "24/09/25 11:49:01 INFO DAGScheduler: Final stage: ResultStage 35 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:49:01 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:49:01 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:49:01 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[75] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:49:01 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 33.9 KiB, free 366.2 MiB)\n",
      "24/09/25 11:49:01 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 366.2 MiB)\n",
      "24/09/25 11:49:01 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 192.168.1.6:41915 (size: 16.3 KiB, free: 366.3 MiB)\n",
      "24/09/25 11:49:01 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:49:01 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 35 (MapPartitionsRDD[75] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11))\n",
      "24/09/25 11:49:01 INFO TaskSchedulerImpl: Adding task set 35.0 with 7 tasks resource profile 0\n",
      "24/09/25 11:49:01 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 128) (192.168.1.6, executor driver, partition 5, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:01 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 129) (192.168.1.6, executor driver, partition 6, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:01 INFO TaskSetManager: Starting task 2.0 in stage 35.0 (TID 130) (192.168.1.6, executor driver, partition 7, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:01 INFO TaskSetManager: Starting task 3.0 in stage 35.0 (TID 131) (192.168.1.6, executor driver, partition 8, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:01 INFO TaskSetManager: Starting task 4.0 in stage 35.0 (TID 132) (192.168.1.6, executor driver, partition 9, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:01 INFO TaskSetManager: Starting task 5.0 in stage 35.0 (TID 133) (192.168.1.6, executor driver, partition 10, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:01 INFO TaskSetManager: Starting task 6.0 in stage 35.0 (TID 134) (192.168.1.6, executor driver, partition 11, PROCESS_LOCAL, 9270 bytes) \n",
      "24/09/25 11:49:01 INFO Executor: Running task 0.0 in stage 35.0 (TID 128)\n",
      "24/09/25 11:49:01 INFO Executor: Running task 1.0 in stage 35.0 (TID 129)\n",
      "24/09/25 11:49:01 INFO Executor: Running task 2.0 in stage 35.0 (TID 130)\n",
      "24/09/25 11:49:01 INFO Executor: Running task 3.0 in stage 35.0 (TID 131)\n",
      "24/09/25 11:49:01 INFO Executor: Running task 4.0 in stage 35.0 (TID 132)\n",
      "24/09/25 11:49:01 INFO Executor: Running task 6.0 in stage 35.0 (TID 134)\n",
      "24/09/25 11:49:01 INFO Executor: Running task 5.0 in stage 35.0 (TID 133)\n",
      "24/09/25 11:49:01 INFO PythonRunner: Times: total = 42, boot = -14069, init = 14111, finish = 0\n",
      "24/09/25 11:49:01 INFO PythonRunner: Times: total = 42, boot = -13955, init = 13997, finish = 0\n",
      "24/09/25 11:49:01 INFO PythonRunner: Times: total = 42, boot = -7481, init = 7523, finish = 0\n",
      "24/09/25 11:49:01 INFO PythonRunner: Times: total = 41, boot = -14065, init = 14106, finish = 0\n",
      "24/09/25 11:49:01 INFO PythonRunner: Times: total = 42, boot = -7480, init = 7522, finish = 0\n",
      "24/09/25 11:49:01 INFO PythonRunner: Times: total = 43, boot = -7487, init = 7530, finish = 0\n",
      "24/09/25 11:49:01 INFO PythonRunner: Times: total = 43, boot = -7480, init = 7523, finish = 0\n",
      "24/09/25 11:49:04 INFO ArrowPythonRunner: Times: total = 2267, boot = -4896, init = 4934, finish = 2229\n",
      "24/09/25 11:49:04 INFO Executor: Finished task 3.0 in stage 35.0 (TID 131). 2137 bytes result sent to driver\n",
      "24/09/25 11:49:04 INFO TaskSetManager: Finished task 3.0 in stage 35.0 (TID 131) in 2281 ms on 192.168.1.6 (executor driver) (1/7)\n",
      "24/09/25 11:49:04 INFO ArrowPythonRunner: Times: total = 2509, boot = -243, init = 285, finish = 2467\n",
      "24/09/25 11:49:04 INFO Executor: Finished task 5.0 in stage 35.0 (TID 133). 2137 bytes result sent to driver\n",
      "24/09/25 11:49:04 INFO TaskSetManager: Finished task 5.0 in stage 35.0 (TID 133) in 2525 ms on 192.168.1.6 (executor driver) (2/7)\n",
      "24/09/25 11:49:04 INFO ArrowPythonRunner: Times: total = 2797, boot = -206, init = 248, finish = 2755\n",
      "24/09/25 11:49:04 INFO Executor: Finished task 0.0 in stage 35.0 (TID 128). 2137 bytes result sent to driver\n",
      "24/09/25 11:49:04 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 128) in 2813 ms on 192.168.1.6 (executor driver) (3/7)\n",
      "The `multi_class` argument has been deprecated and renamed to `multi_label`. `multi_class` will be removed in a future version of Transformers.\n",
      "/home/skumar/miniconda3/envs/spark/lib/python3.8/site-packages/torch/utils/data/dataloader.py:641: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x785041f43b20> was reported to be 2(when accessing len(dataloader)), but 3 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/home/skumar/miniconda3/envs/spark/lib/python3.8/site-packages/torch/utils/data/dataloader.py:641: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x785041f43b20> was reported to be 2(when accessing len(dataloader)), but 4 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/home/skumar/miniconda3/envs/spark/lib/python3.8/site-packages/torch/utils/data/dataloader.py:641: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x785041f43b20> was reported to be 2(when accessing len(dataloader)), but 5 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "24/09/25 11:49:11 INFO ArrowPythonRunner: Times: total = 9381, boot = 5, init = 5681, finish = 3695\n",
      "24/09/25 11:49:11 INFO ArrowPythonRunner: Times: total = 9381, boot = 14, init = 5740, finish = 3627\n",
      "24/09/25 11:49:11 INFO ArrowPythonRunner: Times: total = 9382, boot = 11, init = 5704, finish = 3667\n",
      "24/09/25 11:49:11 INFO Executor: Finished task 2.0 in stage 35.0 (TID 130). 2137 bytes result sent to driver\n",
      "24/09/25 11:49:11 INFO Executor: Finished task 4.0 in stage 35.0 (TID 132). 2180 bytes result sent to driver\n",
      "24/09/25 11:49:11 INFO Executor: Finished task 1.0 in stage 35.0 (TID 129). 2137 bytes result sent to driver\n",
      "24/09/25 11:49:11 INFO TaskSetManager: Finished task 2.0 in stage 35.0 (TID 130) in 9452 ms on 192.168.1.6 (executor driver) (4/7)\n",
      "24/09/25 11:49:11 INFO TaskSetManager: Finished task 4.0 in stage 35.0 (TID 132) in 9453 ms on 192.168.1.6 (executor driver) (5/7)\n",
      "24/09/25 11:49:11 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 129) in 9454 ms on 192.168.1.6 (executor driver) (6/7)\n",
      "/home/skumar/miniconda3/envs/spark/lib/python3.8/site-packages/torch/utils/data/dataloader.py:641: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x785041f43b20> was reported to be 2(when accessing len(dataloader)), but 6 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |MD_RESULT                                                                                                                                                                                                                                                                                                                                                      |\n",
      "+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |[{This text is about consumer strength, 0.9993011}, {This text is about reduced consumer's spending patterns, 1.02624545E-4}, {This text is about consumer weakness, 9.501615E-5}, {This text is about consumer weakness, 0.999502}, {This text is about reduced consumer's spending patterns, 0.9985817}, {This text is about consumer strength, 3.758918E-4}]|\n",
      "+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 11:49:13 INFO ArrowPythonRunner: Times: total = 11323, boot = 365, init = 1, finish = 10957\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 6.0 in stage 35.0 (TID 134). 2354 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 6.0 in stage 35.0 (TID 134) in 11344 ms on 192.168.1.6 (executor driver) (7/7)\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:49:13 INFO DAGScheduler: ResultStage 35 (showString at NativeMethodAccessorImpl.java:0) finished in 11.351 s\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Job 35 finished: showString at NativeMethodAccessorImpl.java:0, took 11.353248 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Apply the UDF\n",
    "result_df = sample_df.withColumn('MD_RESULT', md_inference_udf(col('TEXT_PAIRS_MD')))\n",
    "\n",
    "# Display the results\n",
    "result_df.select(\"id\", \"MD_RESULT\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5b2430e-d821-48e2-935a-9cd227a02670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 11:49:13 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Got job 36 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Final stage: ResultStage 36 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[77] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:49:13 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 14.4 KiB, free 366.2 MiB)\n",
      "24/09/25 11:49:13 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 366.2 MiB)\n",
      "24/09/25 11:49:13 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 192.168.1.6:41915 (size: 7.1 KiB, free: 366.3 MiB)\n",
      "24/09/25 11:49:13 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[77] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 135) (192.168.1.6, executor driver, partition 0, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO Executor: Running task 0.0 in stage 36.0 (TID 135)\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 44, boot = -11346, init = 11390, finish = 0\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 0.0 in stage 36.0 (TID 135). 1843 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 135) in 49 ms on 192.168.1.6 (executor driver) (1/1)\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:49:13 INFO DAGScheduler: ResultStage 36 (showString at NativeMethodAccessorImpl.java:0) finished in 0.056 s\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Job 36 finished: showString at NativeMethodAccessorImpl.java:0, took 0.059602 s\n",
      "24/09/25 11:49:13 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Got job 37 (showString at NativeMethodAccessorImpl.java:0) with 4 output partitions\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Final stage: ResultStage 37 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[77] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:49:13 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 14.4 KiB, free 366.1 MiB)\n",
      "24/09/25 11:49:13 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 366.1 MiB)\n",
      "24/09/25 11:49:13 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 192.168.1.6:41915 (size: 7.1 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:49:13 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 37 (MapPartitionsRDD[77] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(1, 2, 3, 4))\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Adding task set 37.0 with 4 tasks resource profile 0\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 136) (192.168.1.6, executor driver, partition 1, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 137) (192.168.1.6, executor driver, partition 2, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 138) (192.168.1.6, executor driver, partition 3, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 139) (192.168.1.6, executor driver, partition 4, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO Executor: Running task 0.0 in stage 37.0 (TID 136)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 1.0 in stage 37.0 (TID 137)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 2.0 in stage 37.0 (TID 138)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 3.0 in stage 37.0 (TID 139)\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 41, boot = -11408, init = 11449, finish = 0\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 41, boot = -11409, init = 11450, finish = 0\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 42, boot = -11409, init = 11451, finish = 0\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 42, boot = -11409, init = 11451, finish = 0\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 3.0 in stage 37.0 (TID 139). 1843 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 139) in 48 ms on 192.168.1.6 (executor driver) (1/4)\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 2.0 in stage 37.0 (TID 138). 1843 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 0.0 in stage 37.0 (TID 136). 1843 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 138) in 49 ms on 192.168.1.6 (executor driver) (2/4)\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 136) in 51 ms on 192.168.1.6 (executor driver) (3/4)\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 1.0 in stage 37.0 (TID 137). 1886 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 137) in 57 ms on 192.168.1.6 (executor driver) (4/4)\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:49:13 INFO DAGScheduler: ResultStage 37 (showString at NativeMethodAccessorImpl.java:0) finished in 0.062 s\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Job 37 finished: showString at NativeMethodAccessorImpl.java:0, took 0.065041 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|TEXT_PAIRS_MD                                                                                                                                                                                                                                               |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[Consumers are showing increased confidence in the market, leading to higher spending.<s><s>This text is about consumer strength], [There is a noticeable decline in consumer purchasing behavior this quarter.<s><s>This text is about consumer weakness]]|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 11:49:13 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Got job 38 (showString at NativeMethodAccessorImpl.java:0) with 7 output partitions\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Final stage: ResultStage 38 (showString at NativeMethodAccessorImpl.java:0)\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Parents of final stage: List()\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Missing parents: List()\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[77] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "24/09/25 11:49:13 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 14.4 KiB, free 366.1 MiB)\n",
      "24/09/25 11:49:13 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 366.1 MiB)\n",
      "24/09/25 11:49:13 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 192.168.1.6:41915 (size: 7.1 KiB, free: 366.2 MiB)\n",
      "24/09/25 11:49:13 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1585\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Submitting 7 missing tasks from ResultStage 38 (MapPartitionsRDD[77] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11))\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Adding task set 38.0 with 7 tasks resource profile 0\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 140) (192.168.1.6, executor driver, partition 5, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 141) (192.168.1.6, executor driver, partition 6, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 142) (192.168.1.6, executor driver, partition 7, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 143) (192.168.1.6, executor driver, partition 8, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 4.0 in stage 38.0 (TID 144) (192.168.1.6, executor driver, partition 9, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 5.0 in stage 38.0 (TID 145) (192.168.1.6, executor driver, partition 10, PROCESS_LOCAL, 8979 bytes) \n",
      "24/09/25 11:49:13 INFO TaskSetManager: Starting task 6.0 in stage 38.0 (TID 146) (192.168.1.6, executor driver, partition 11, PROCESS_LOCAL, 9270 bytes) \n",
      "24/09/25 11:49:13 INFO Executor: Running task 0.0 in stage 38.0 (TID 140)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 2.0 in stage 38.0 (TID 142)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 3.0 in stage 38.0 (TID 143)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 1.0 in stage 38.0 (TID 141)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 5.0 in stage 38.0 (TID 145)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 4.0 in stage 38.0 (TID 144)\n",
      "24/09/25 11:49:13 INFO Executor: Running task 6.0 in stage 38.0 (TID 146)\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 41, boot = -11477, init = 11518, finish = 0\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 41, boot = -11476, init = 11517, finish = 0\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 41, boot = -71, init = 112, finish = 0\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 42, boot = -10, init = 52, finish = 0\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 42, boot = -9, init = 51, finish = 0\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 43, boot = -11, init = 54, finish = 0\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 5.0 in stage 38.0 (TID 145). 1843 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 0.0 in stage 38.0 (TID 140). 1886 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 3.0 in stage 38.0 (TID 143). 1886 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 6.0 in stage 38.0 (TID 146). 2075 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 140) in 48 ms on 192.168.1.6 (executor driver) (1/7)\n",
      "24/09/25 11:49:13 INFO PythonRunner: Times: total = 43, boot = -15, init = 58, finish = 0\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 5.0 in stage 38.0 (TID 145) in 49 ms on 192.168.1.6 (executor driver) (2/7)\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 2.0 in stage 38.0 (TID 142). 1843 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 6.0 in stage 38.0 (TID 146) in 49 ms on 192.168.1.6 (executor driver) (3/7)\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 4.0 in stage 38.0 (TID 144). 1886 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 143) in 49 ms on 192.168.1.6 (executor driver) (4/7)\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 142) in 50 ms on 192.168.1.6 (executor driver) (5/7)\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 4.0 in stage 38.0 (TID 144) in 50 ms on 192.168.1.6 (executor driver) (6/7)\n",
      "24/09/25 11:49:13 INFO Executor: Finished task 1.0 in stage 38.0 (TID 141). 1843 bytes result sent to driver\n",
      "24/09/25 11:49:13 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 141) in 52 ms on 192.168.1.6 (executor driver) (7/7)\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool \n",
      "24/09/25 11:49:13 INFO DAGScheduler: ResultStage 38 (showString at NativeMethodAccessorImpl.java:0) finished in 0.058 s\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "24/09/25 11:49:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 38: Stage finished\n",
      "24/09/25 11:49:13 INFO DAGScheduler: Job 38 finished: showString at NativeMethodAccessorImpl.java:0, took 0.060368 s\n",
      "24/09/25 12:00:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.1.6:41915 in memory (size: 7.2 KiB, free: 366.2 MiB)\n",
      "24/09/25 12:00:00 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 192.168.1.6:41915 in memory (size: 7.1 KiB, free: 366.3 MiB)\n",
      "24/09/25 12:00:00 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 192.168.1.6:41915 in memory (size: 16.3 KiB, free: 366.3 MiB)\n",
      "24/09/25 12:00:00 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 192.168.1.6:41915 in memory (size: 7.1 KiB, free: 366.3 MiB)\n",
      "24/09/25 12:00:00 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 192.168.1.6:41915 in memory (size: 16.3 KiB, free: 366.3 MiB)\n",
      "24/09/25 12:00:00 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 192.168.1.6:41915 in memory (size: 7.1 KiB, free: 366.3 MiB)\n"
     ]
    }
   ],
   "source": [
    "result_df.select('TEXT_PAIRS_MD').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e95da2-7016-4747-bb65-b026f622f14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
